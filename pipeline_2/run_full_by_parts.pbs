#!/bin/bash
#PBS -q normal
#PBS -l select=1:ncpus=24:mem=60G
#PBS -l walltime=90:00:00
#PBS -P personal-tancsc
#PBS -N rerun_08
n=topup

## Extract unmapped read and mates from CRAM files ##
# Input: CRAM file
# Output: fastq file containing read and mates

source ~/miniconda3/etc/profile.d/conda.sh
conda activate metagenomics

WKDIR=/scratch/users/astar/gis/tancsc/blood_microbiome_files_2
SCRIPTS=/home/projects/14001280/PROJECTS/blood_microbiome/pipeline_2
N_THREADS=24

# Create directories 
mkdir ${WKDIR}
mkdir ${WKDIR}/01_bam ${WKDIR}/01_fastq/ ${WKDIR}/02_fastq/ ${WKDIR}/03_fastq/ ${WKDIR}/04_fastq/ ${WKDIR}/05_fastq/ ${WKDIR}/06_reports/ ${WKDIR}/06_unclassified_fastq/ ${WKDIR}/07_abundance_matrix/

while read line
do
        COHORT=$(echo $line | awk '{split($0, a, ","); print a[1]}')
        MUX=$(echo $line | awk '{split($0, a, ","); print a[2]}')
        SAMPLE=$(echo $line | awk '{split($0, a, ","); print a[3]}')

	echo $COHORT $MUX $SAMPLE
        # Step 1: Extract unmapped read and mates from CRAM files
        #sh ${SCRIPTS}/extract_unmapped_reads_and_mates.sh $COHORT $MUX $SAMPLE $WKDIR $N_THREADS 1

        # Step 2: Remove reads with only Ns
        sh ${SCRIPTS}/remove_Ns.sh $COHORT $MUX $SAMPLE $WKDIR $N_THREADS 2

        # Step 3: Quality trimming
        sh ${SCRIPTS}/quality_trim.sh $COHORT $MUX $SAMPLE $WKDIR $N_THREADS 3

        # Step 4: Quality filtering
        sh ${SCRIPTS}/quality_filter.sh $COHORT $MUX $SAMPLE $WKDIR $N_THREADS 4

        # Step 5: Remove low complexity reads
        sh ${SCRIPTS}/remove_low_complexity.sh $COHORT $MUX $SAMPLE $WKDIR $N_THREADS 5

        # Step 6: Kraken2 classification
        sh ${SCRIPTS}/kraken2_assignment.sh $COHORT $MUX $SAMPLE $WKDIR $N_THREADS 6
        
done < /home/projects/14001280/PROJECTS/blood_microbiome/data/file_lists/n9970_list_part_${n}.csv

echo -------SCRIPT COMPLETE------- 
