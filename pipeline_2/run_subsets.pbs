#!/bin/bash
#PBS -q normal
#PBS -l select=1:ncpus=5:mem=10G
#PBS -l walltime=10:00:00
#PBS -P 14001280
#PBS -N subset_10_pipeline_2
## Extract unmapped read and mates from CRAM files ##
# Input: CRAM file
# Output: fastq file containing read and mates

source ~/miniconda3/etc/profile.d/conda.sh
conda activate metameta
n_subset=10
WKDIR=/home/projects/14001280/PROJECTS/blood_microbiome/data/temp_files_${n_subset}.pipeline_2
SCRIPTS=/home/projects/14001280/PROJECTS/blood_microbiome/pipeline_2
N_THREADS=5

# Create directories 
mkdir ${WKDIR}
mkdir ${WKDIR}/01_bam ${WKDIR}/01_files/ ${WKDIR}/02_files/ ${WKDIR}/03_files/ ${WKDIR}/04_files/ ${WKDIR}/05_files/ ${WKDIR}/06_reports/ ${WKDIR}/06_unclassified_fastq/ ${WKDIR}/07_abundance_matrix/

while read line
do
        COHORT=$(echo $line | awk '{split($0, a, ","); print a[1]}')
        MUX=$(echo $line | awk '{split($0, a, ","); print a[2]}')
        SAMPLE=$(echo $line | awk '{split($0, a, ","); print a[3]}')

	echo $COHORT $MUX $SAMPLE
        
	# Step 1: Extract unmapped read and mates from CRAM files
        sh ${SCRIPTS}/extract_unmapped_reads_and_mates.sh $COHORT $MUX $SAMPLE $WKDIR $N_THREADS 1
	
	# Step 2: Remove reads with only Ns
	sh ${SCRIPTS}/remove_Ns.sh $COHORT $MUX $SAMPLE $WKDIR $N_THREADS 2

	# Step 3: Quality trimming        
	sh ${SCRIPTS}/quality_trim.sh $COHORT $MUX $SAMPLE $WKDIR $N_THREADS 3
	
        # Step 4: Quality filtering
        sh ${SCRIPTS}/quality_filter.sh $COHORT $MUX $SAMPLE $WKDIR $N_THREADS 4
        
	# Step 5: Remove low complexity reads
	sh ${SCRIPTS}/remove_low_complexity.sh $COHORT $MUX $SAMPLE $WKDIR $N_THREADS 5
        
        # Step 6: Kraken2 classification
        sh ${SCRIPTS}/kraken2_assignment.sh $COHORT $MUX $SAMPLE $WKDIR $N_THREADS 6
	
done < ${WKDIR}/../subset_list_${n_subset}.csv

# Step 7: Parse Kraken2 reports
sh ${SCRIPTS}/parse_kraken2_report.sh $n_subset $WKDIR $SCRIPTS 7
echo -------SCRIPT COMPLETE------- 
